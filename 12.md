Stochastic Gradient Descent (SGD) is an iterative optimization algorithm
used to minimize the loss function (error) of a neural network by
adjusting the weights and biases of the network during training. Here\'s
how it works:

1\. Stochastic: In traditional Gradient Descent, you compute the
gradient of the loss with respect to all training examples, which can be
computationally expensive, especially for large datasets. In SGD, you
randomly select a small subset (mini-batch) of training examples
(typically 32, 64, or 128) at each iteration and update the model\'s
parameters based on the gradient of the loss computed for this
mini-batch.

2\. Gradient: The gradient is the direction of the steepest increase in
the loss function. SGD calculates the gradient of the loss with respect
to the model\'s parameters, indicating how to adjust the parameters to
minimize the loss.

3\. Descent: \"Descent\" indicates that the algorithm aims to move in
the direction opposite to the gradient. The goal is to find the
parameters that minimize the loss function, which is achieved by
iteratively adjusting the parameters in the direction of the negative
gradient.

SGD is preferred over batch gradient descent for several reasons:

\- Faster Convergence: Since SGD updates the model parameters more
frequently, it can converge faster, especially when dealing with large
datasets.

\- Regularization: The randomness introduced by using mini-batches can
act as a form of regularization, helping prevent overfitting.

\- Parallelization: Mini-batch processing can be easily parallelized,
making it efficient for training on GPUs or distributed systems.

\- Escape Local Minima: The stochastic nature of SGD can help the
algorithm escape local minima in the loss landscape.

In practice, variations of SGD are often used, such as momentum,
RMSprop, and Adam, to further enhance convergence and training
stability.

Sure, here are the equations for the Stochastic Gradient Descent (SGD)
algorithm. The goal of SGD is to minimize a loss function J(θ) by
updating the model parameters θ iteratively. The parameters are
typically weights and biases in the context of training a neural
network.

1\. Initialization: Initialize the model parameters θ with some initial
values.

2\. Choose a Learning Rate: Select a learning rate α that determines the
step size for parameter updates. The learning rate is usually a small
positive value.

3\. Iterative Updates:

For each iteration, do the following:

a\. Mini-Batch Sampling: Randomly select a mini-batch of training
examples from the dataset. Let this mini-batch be denoted as MiniBatch.

b\. Compute the Gradient: Compute the gradient of the loss function with
respect to the parameters for the mini-batch. This is often denoted as
∇J(θ; MiniBatch).

c\. Update Parameters: Update the model parameters using the gradient
information and the learning rate. The update equation is as follows:

θ ← θ - α∇J(θ; MiniBatch)

This update is performed for each parameter θi in θ, and the learning
rate α controls the step size in the direction of the negative gradient.

4\. Stopping Criteria: Repeat the iterative updates until a stopping
criterion is met. Common stopping criteria include a fixed number of
iterations, convergence of the loss, or other conditions based on the
specific problem.

The key equation in SGD is the parameter update step, which is
responsible for moving the parameters in the direction that reduces the
loss. The learning rate α determines the size of the step, and the
negative gradient ∇J(θ; MiniBatch) indicates the direction of steepest
descent in the loss landscape.

In practice, variations of SGD, like mini-batch size, learning rate
schedules, and momentum, are often used to improve convergence and
training efficiency.

Problem: We want to fit a straight line to a set of data points using
SGD.

Linear Regression Model: The linear regression model has the form y =
mx + b, where m is the slope and b is the y-intercept. Our goal is to
find the values of m and b that best fit the data

Loss Function: We\'ll use the mean squared error (MSE) as the loss
function to minimize:

J(m, b) = (1/2N)Σ(yi - (mx + b))\^2

Where:

\- N is the number of data points.

\- xi and yi are the coordinates of the data points.

SGD Algorithm:

1\. Initialize m and b with some initial values, e.g., m = 0 and b = 0.

2\. Choose a learning rate, e.g., α = 0.01.

3\. Repeat for a fixed number of iterations or until convergence:

a\. Randomly select a data point from the dataset.

b\. Calculate the gradient of the loss with respect to m and b for the
selected data point.

∂J/∂m = -(yi - (mx + b))xi

∂J/∂b = -(yi - (mx + b))

c\. Update m and b using the gradients and the learning rate:

m ← m + α(∂J/∂m)

b ← b + α(∂J/∂b)

Sample Data:

Let\'s consider a dataset with three data points:

Data point 1: (x1, y1) = (2, 3)

Data point 2: (x2, y2) = (4, 5)

Data point 3: (x3, y3) = (6, 7)

SGD Steps:

Let\'s perform one iteration of SGD using the provided data and initial
values of m and b. We\'ll use α = 0.01.

1\. Initialize m = 0 and b = 0.

2\. Select a random data point (e.g., data point 2: x2 = 4, y2 = 5).

3\. Compute the gradients:

∂J/∂m = -(5 - (4m + b)) \* 4 = -(5 - (4 \* 0 + 0)) \* 4 = -5 \* 4 = -20

∂J/∂b = -(5 - (4m + b)) = -(5 - (4 \* 0 + 0)) = -5

4\. Update m and b:

m ← m + α(∂J/∂m) = 0 + 0.01 \* (-20) = -0.2

b ← b + α(∂J/∂b) = 0 + 0.01 \* (-5) = -0.05

After this iteration, the values of m and b have been updated. You would
repeat these steps for a fixed number of iterations or until convergence
to find the best-fitting line for the given data points.
